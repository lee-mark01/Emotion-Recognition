# 📸 실시간 웹캠 감정 인식 프로젝트 (FER 라이브러리 활용)

이 프로젝트는 Google Colab 환경에서 웹캠으로 실시간 사진을 촬영하고, **FER (Face Emotion Recognition)** 라이브러리를 사용해 이미지 속 얼굴의 감정을 분석하는 간단한 애플리케이션입니다.

## 🎯 프로젝트 개요

웹캠을 통해 사용자의 얼굴을 촬영한 후, `fer` 라이브러리에 내장된 딥러닝 모델이 **7가지 주요 감정(angry, disgust, fear, happy, sad, surprise, neutral)** 중 가장 확률이 높은 감정을 식별하고 신뢰도 점수와 함께 출력합니다.

## 🛠️ 주요 기술

* **Python**
* **Google Colab (개발 환경)**
* **FER (Face Emotion Recognition):** 감정 인식을 위한 핵심 라이브러리
* **MTCNN (Multi-task Cascaded Convolutional Networks):** 얼굴 감지를 위한 딥러닝 모델
* **TensorFlow / PyTorch:** FER 라이브러리의 백엔드 딥러닝 프레임워크
* **OpenCV, PIL:** 이미지 처리
* **IPython.display, google.colab.output:** Colab 환경에서 웹캠을 제어하기 위한 도구

## 🚀 실행 방법

본 프로젝트는 Google Colab 환경에서 가장 쉽게 실행할 수 있습니다.

1.  `emotion_recognition.ipynb` 파일을 Google Colab에서 엽니다.

2.  **런타임 유형 변경:**
    상단 메뉴에서 **[런타임] > [런타임 유형 변경]**을 클릭하고, 하드웨어 가속기를 **GPU**로 설정하면 더 빠른 성능을 경험할 수 있습니다.

3.  **셀 순차적 실행:**
    노트북의 각 코드 셀을 위에서부터 순서대로 실행합니다.
    * **라이브러리 설치 셀:** `fer`, `torch` 등 필요한 라이브러리를 설치합니다.
    * **사진 촬영 셀:** 실행하면 웹캠 화면과 함께 사진 촬영 버튼이 나타납니다. 브라우저에서 카메라 접근 권한을 요청하면 **[허용]**을 클릭해야 합니다. 버튼을 눌러 사진을 촬영하면 `photo.jpg` 파일이 Colab 환경에 저장됩니다.
    * **감정 인식 셀:** 촬영된 `photo.jpg` 파일을 불러와 얼굴을 감지하고, 가장 지배적인 감정을 분석하여 결과를 출력합니다.

## 📊 결과 예시

```
😊 감정 분석 결과: happy (0.98)
```
또는
```
❗ 얼굴을 감지하지 못했습니다.
```

## 💡 원리 및 구조

1.  **웹캠 제어:** `google.colab.output`과 `IPython.display`를 사용해 브라우저의 JavaScript 기능을 호출하여 웹캠 스트림을 활성화하고 사진을 캡처합니다.
2.  **얼굴 감지:** `FER(mtcnn=True)` 옵션을 통해 MTCNN 모델이 이미지에서 얼굴 영역을 먼저 찾아냅니다.
3.  **감정 분류:** 감지된 얼굴 영역을 FER 라이브러리의 감정 분류 모델에 입력합니다. 이 모델은 7가지 감정에 대한 확률 값을 출력합니다.
4.  **결과 출력:** 가장 높은 확률 값을 가진 감정을 '최종 감정'으로 선택하여 신뢰도 점수와 함께 표시합니다.

## 📜 라이선스

본 프로젝트는 [MIT License](LICENSE)를 따릅니다.
